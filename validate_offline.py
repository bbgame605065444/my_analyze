#!/usr/bin/env python3
"""
ç¦»çº¿æ¨¡å¼éªŒè¯è„šæœ¬
éªŒè¯ç³»ç»Ÿæ˜¯å¦æ­£ç¡®é…ç½®ä¸ºä»…ä½¿ç”¨Qwen3æœ¬åœ°æ¨ç†ï¼Œæ— ä»»ä½•åœ¨çº¿APIä¾èµ–

CoTå­¦ä¹ è¦ç‚¹ï¼š
- è¿™ä¸ªè„šæœ¬ç¡®ä¿ç³»ç»ŸçœŸæ­£ç¦»çº¿è¿è¡Œ
- éªŒè¯æ‰€æœ‰åœ¨çº¿APIéƒ½è¢«ç¦ç”¨
- æµ‹è¯•Qwen3æœ¬åœ°æ¨ç†æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import importlib
import subprocess
from pathlib import Path

def print_section(title):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"ğŸ” {title}")
    print(f"{'='*60}")

def check_offline_config():
    """æ£€æŸ¥ç¦»çº¿é…ç½®"""
    print_section("æ£€æŸ¥ç¦»çº¿é…ç½®")
    
    # æ£€æŸ¥.envæ–‡ä»¶
    env_file = Path(".env")
    if not env_file.exists():
        print("âŒ .envé…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    print("âœ… .envé…ç½®æ–‡ä»¶å­˜åœ¨")
    
    # è¯»å–é…ç½®
    with open(env_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ£€æŸ¥å…³é”®é…ç½®
    checks = [
        ("OFFLINE_MODE=true", "ç¦»çº¿æ¨¡å¼å¯ç”¨"),
        ("MODEL_TYPE=qwen3_local", "æ¨¡å‹ç±»å‹è®¾ç½®ä¸ºæœ¬åœ°æ¨ç†"),
        ("QWEN_MODEL_PATH=Qwen/Qwen3-8B", "Qwen3æ¨¡å‹è·¯å¾„é…ç½®")
    ]
    
    all_good = True
    for config_line, description in checks:
        if config_line in content:
            print(f"âœ… {description}")
        else:
            print(f"âŒ {description} - æœªæ‰¾åˆ°: {config_line}")
            all_good = False
    
    return all_good

def check_forbidden_imports():
    """æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¢«ç¦æ­¢çš„åœ¨çº¿APIå¯¼å…¥"""
    print_section("æ£€æŸ¥ç¦æ­¢çš„åœ¨çº¿APIå¯¼å…¥")
    
    forbidden_modules = [
        "google.generativeai", 
        "openai",
        "anthropic",
        "cohere"
    ]
    
    all_good = True
    for module in forbidden_modules:
        try:
            importlib.import_module(module)
            print(f"âš ï¸ æ£€æµ‹åˆ°åœ¨çº¿APIæ¨¡å—: {module} (å·²å®‰è£…ä½†åº”åœ¨ç¦»çº¿æ¨¡å¼ä¸‹ç¦ç”¨)")
            # æ³¨æ„ï¼šè¿™é‡Œä¸ç®—ä½œé”™è¯¯ï¼Œå› ä¸ºæ¨¡å—å¯èƒ½å·²å®‰è£…ä½†ä¸ä¼šè¢«ä½¿ç”¨
        except ImportError:
            print(f"âœ… åœ¨çº¿APIæ¨¡å— {module} æœªå®‰è£… (ç¬¦åˆç¦»çº¿è¦æ±‚)")
    
    return all_good

def check_required_dependencies():
    """æ£€æŸ¥å¿…éœ€çš„ä¾èµ–"""
    print_section("æ£€æŸ¥Qwen3å¿…éœ€ä¾èµ–")
    
    required_modules = [
        ("torch", "PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶"),
        ("transformers", "HuggingFace Transformers"),
        ("accelerate", "æ¨¡å‹åŠ é€Ÿåº“"),
        ("numpy", "æ•°å€¼è®¡ç®—åº“"),
        ("dotenv", "ç¯å¢ƒå˜é‡ç®¡ç†")
    ]
    
    all_good = True
    for module, description in required_modules:
        try:
            mod = importlib.import_module(module)
            version = getattr(mod, '__version__', 'unknown')
            print(f"âœ… {description}: {module} v{version}")
        except ImportError:
            print(f"âŒ {description}: {module} æœªå®‰è£…")
            all_good = False
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            print(f"âœ… CUDAå¯ç”¨ï¼ŒGPUæ•°é‡: {gpu_count}")
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                memory = torch.cuda.get_device_properties(i).total_memory // (1024**3)
                print(f"   GPU {i}: {gpu_name} ({memory}GB)")
        else:
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨ç† (é€Ÿåº¦è¾ƒæ…¢)")
    except Exception as e:
        print(f"âŒ CUDAæ£€æŸ¥å¤±è´¥: {e}")
        all_good = False
    
    return all_good

def test_model_interface():
    """æµ‹è¯•æ¨¡å‹æ¥å£"""
    print_section("æµ‹è¯•æ¨¡å‹æ¥å£")
    
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡ç¡®ä¿ç¦»çº¿æ¨¡å¼
        os.environ['OFFLINE_MODE'] = 'true'
        os.environ['MODEL_TYPE'] = 'qwen3_local'
        
        from model_interface import get_model_response, OFFLINE_MODE, TRANSFORMERS_AVAILABLE
        from model_config import ConfigManager
        
        print(f"âœ… æ¨¡å‹æ¥å£å¯¼å…¥æˆåŠŸ")
        print(f"âœ… ç¦»çº¿æ¨¡å¼çŠ¶æ€: {OFFLINE_MODE}")
        print(f"âœ… Transformerså¯ç”¨: {TRANSFORMERS_AVAILABLE}")
        
        # æµ‹è¯•é…ç½®åŠ è½½
        config_manager = ConfigManager()
        config = config_manager.get_config()
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: æ¨¡å‹ç±»å‹ = {config.model_type}")
        
        # æµ‹è¯•åœ¨çº¿APIæ˜¯å¦è¢«æ­£ç¡®ç¦ç”¨
        try:
            # å°è¯•ä½¿ç”¨Gemini API (åº”è¯¥è¢«é˜»æ­¢)
            config.model_type = 'gemini'
            get_model_response("test", config)
            print("âŒ Gemini APIæœªè¢«æ­£ç¡®ç¦ç”¨")
            return False
        except ValueError as e:
            if "ç¦»çº¿æ¨¡å¼ä¸‹ç¦ç”¨" in str(e):
                print("âœ… Gemini APIæ­£ç¡®è¢«ç¦ç”¨")
            else:
                print(f"âŒ æ„å¤–é”™è¯¯: {e}")
                return False
        
        # æµ‹è¯•æœ¬åœ°æ¨ç†æ˜¯å¦å¯ç”¨
        config.model_type = 'qwen3_local'
        print("ğŸ”„ å‡†å¤‡æµ‹è¯•Qwen3æœ¬åœ°æ¨ç†...")
        
        # æ³¨æ„ï¼šè¿™é‡Œä¸å®é™…åŠ è½½æ¨¡å‹ï¼Œå› ä¸ºå¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´
        print("âœ… æ¨¡å‹æ¥å£éªŒè¯å®Œæˆ (æœªå®é™…åŠ è½½æ¨¡å‹ä»¥èŠ‚çœæ—¶é—´)")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ¥å£æµ‹è¯•å¤±è´¥: {e}")
        return False

def check_network_isolation():
    """æ£€æŸ¥ç½‘ç»œéš”ç¦»çŠ¶æ€"""
    print_section("æ£€æŸ¥ç½‘ç»œéš”ç¦»")
    
    # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†ç¦»çº¿ç¯å¢ƒå˜é‡
    offline_mode = os.getenv('OFFLINE_MODE', 'false').lower() == 'true'
    if offline_mode:
        print("âœ… OFFLINE_MODEç¯å¢ƒå˜é‡å·²è®¾ç½®")
    else:
        print("âš ï¸ OFFLINE_MODEç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œå»ºè®®è®¾ç½®ä¸ºtrue")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç½‘ç»œç›¸å…³çš„ç¯å¢ƒå˜é‡è¢«ç¦ç”¨
    api_vars = ['GEMINI_API_KEY', 'OPENAI_API_KEY', 'API_KEY']
    for var in api_vars:
        value = os.getenv(var)
        if value and not value.startswith('disabled'):
            print(f"âš ï¸ æ£€æµ‹åˆ°APIå¯†é’¥ç¯å¢ƒå˜é‡ {var}ï¼Œç¦»çº¿æ¨¡å¼ä¸‹ä¼šè¢«å¿½ç•¥")
        else:
            print(f"âœ… APIå¯†é’¥ {var} æœªè®¾ç½®æˆ–å·²ç¦ç”¨")
    
    return True

def generate_offline_report():
    """ç”Ÿæˆç¦»çº¿éªŒè¯æŠ¥å‘Š"""
    print_section("ç”ŸæˆéªŒè¯æŠ¥å‘Š")
    
    report_file = "offline_validation_report.txt"
    
    # æ”¶é›†ç³»ç»Ÿä¿¡æ¯
    import platform
    import datetime
    
    try:
        import torch
        torch_version = torch.__version__
        cuda_available = torch.cuda.is_available()
        cuda_version = torch.version.cuda if cuda_available else "N/A"
    except ImportError:
        torch_version = "Not installed"
        cuda_available = False
        cuda_version = "N/A"
    
    try:
        import transformers
        transformers_version = transformers.__version__
    except ImportError:
        transformers_version = "Not installed"
    
    report_content = f"""
CoT ç¦»çº¿æ¨¡å¼éªŒè¯æŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.datetime.now()}

=== ç³»ç»Ÿä¿¡æ¯ ===
æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}
Pythonç‰ˆæœ¬: {platform.python_version()}
æ¶æ„: {platform.machine()}

=== ä¾èµ–ç‰ˆæœ¬ ===
PyTorch: {torch_version}
Transformers: {transformers_version}
CUDAå¯ç”¨: {cuda_available}
CUDAç‰ˆæœ¬: {cuda_version}

=== ç¦»çº¿é…ç½® ===
ç¦»çº¿æ¨¡å¼: {os.getenv('OFFLINE_MODE', 'false')}
æ¨¡å‹ç±»å‹: {os.getenv('MODEL_TYPE', 'not set')}
Qwenæ¨¡å‹è·¯å¾„: {os.getenv('QWEN_MODEL_PATH', 'not set')}
FP8é‡åŒ–: {os.getenv('USE_FP8', 'false')}

=== éªŒè¯çŠ¶æ€ ===
é…ç½®æ–‡ä»¶: {'å­˜åœ¨' if Path('.env').exists() else 'ä¸å­˜åœ¨'}
å¿…éœ€ä¾èµ–: {'å®Œæ•´' if torch_version != 'Not installed' and transformers_version != 'Not installed' else 'ç¼ºå¤±'}
ç¦»çº¿æ¨¡å¼: {'å·²å¯ç”¨' if os.getenv('OFFLINE_MODE', 'false').lower() == 'true' else 'æœªå¯ç”¨'}

=== å»ºè®® ===
1. ç¡®ä¿æ‰€æœ‰å¿…éœ€ä¾èµ–å·²å®‰è£…
2. éªŒè¯ç¦»çº¿é…ç½®æ­£ç¡®è®¾ç½®
3. æµ‹è¯•Qwen3æ¨¡å‹æ¨ç†åŠŸèƒ½
4. æ£€æŸ¥GPUå†…å­˜æ˜¯å¦è¶³å¤Ÿ (æ¨è12GB+)

æ­¤æŠ¥å‘Šç¡®è®¤ç³»ç»Ÿå·²é…ç½®ä¸ºç¦»çº¿æ¨¡å¼ï¼Œä»…ä½¿ç”¨Qwen3æœ¬åœ°æ¨ç†ã€‚
"""
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"âœ… éªŒè¯æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
    return True

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("ğŸ”’ CoT ç¦»çº¿æ¨¡å¼éªŒè¯å·¥å…·")
    print("éªŒè¯ç³»ç»Ÿæ˜¯å¦æ­£ç¡®é…ç½®ä¸ºä»…ä½¿ç”¨Qwen3æœ¬åœ°æ¨ç†")
    
    # å¼ºåˆ¶è®¾ç½®ç¦»çº¿æ¨¡å¼
    os.environ['OFFLINE_MODE'] = 'true'
    
    results = []
    
    # æ‰§è¡Œå„é¡¹æ£€æŸ¥
    results.append(("é…ç½®æ£€æŸ¥", check_offline_config()))
    results.append(("ä¾èµ–æ£€æŸ¥", check_required_dependencies()))
    results.append(("ç¦æ­¢æ¨¡å—æ£€æŸ¥", check_forbidden_imports()))
    results.append(("æ¨¡å‹æ¥å£æµ‹è¯•", test_model_interface()))
    results.append(("ç½‘ç»œéš”ç¦»æ£€æŸ¥", check_network_isolation()))
    results.append(("ç”ŸæˆæŠ¥å‘Š", generate_offline_report()))
    
    # æ±‡æ€»ç»“æœ
    print_section("éªŒè¯ç»“æœæ±‡æ€»")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} é¡¹æ£€æŸ¥é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ­å–œï¼ç³»ç»Ÿå·²æˆåŠŸé…ç½®ä¸ºç¦»çº¿æ¨¡å¼")
        print("ç°åœ¨å¯ä»¥å®‰å…¨åœ°è¿è¡ŒCoTå®éªŒï¼Œæ‰€æœ‰æ¨ç†éƒ½å°†åœ¨æœ¬åœ°å®Œæˆ")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œ python main.py å¼€å§‹CoTå®éªŒ")
        print("2. è¿è¡Œ python run_tests.py è¿›è¡ŒåŠŸèƒ½æµ‹è¯•")
        print("3. æ£€æŸ¥ offline_validation_report.txt äº†è§£è¯¦ç»†ä¿¡æ¯")
    else:
        print(f"\nâš ï¸ æ£€æµ‹åˆ° {total - passed} ä¸ªé—®é¢˜ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºè¿›è¡Œä¿®å¤")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)