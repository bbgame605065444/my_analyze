# CoT 实验依赖库

# 核心依赖 (必需)
numpy>=1.21.0

# Gemini API支持 (可选 - 使用Gemini时需要)
google-generativeai>=0.3.0

# Qwen3本地推理支持 (可选 - 使用Qwen3本地推理时需要)
torch>=2.0.0
transformers>=4.51.0
accelerate>=0.20.0

# FP8量化支持 (可选 - 启用FP8量化时需要)
bitsandbytes>=0.41.0

# Qwen3 API支持 (可选 - 使用OpenAI兼容API时需要)
openai>=1.0.0

# 配置管理 (可选 - 使用配置文件时需要)
python-dotenv>=0.19.0

# 开发和测试工具 (可选)
pytest>=7.0.0
pytest-cov>=4.0.0

# 性能优化 (可选)
flash-attn>=2.0.0  # 注意：需要CUDA支持

# 说明:
# 1. 根据你选择的模型类型安装相应的依赖
# 2. 对于Qwen3本地推理，推荐安装CUDA版本的PyTorch以获得最佳性能
# 3. FP8量化需要较新的GPU (如RTX 40系列)
# 4. flash-attn需要编译，可能安装时间较长