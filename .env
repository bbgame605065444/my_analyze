# CoT 实验离线配置文件 - 仅使用 Qwen3 本地推理
# 此配置确保系统完全离线运行，不使用任何在线API

# =============================================================================
# 离线模式配置 (OFFLINE MODE)
# =============================================================================

# 启用离线模式 - 禁用所有在线API
OFFLINE_MODE=true

# 模型类型: 强制使用本地推理
MODEL_TYPE=qwen3_local

# =============================================================================
# Qwen3 本地推理配置
# =============================================================================

# Qwen3模型路径 (HuggingFace模型名称或本地路径)
QWEN_MODEL_PATH=Qwen/Qwen3-8B

# 是否启用FP8量化 (推荐启用以提升性能)
USE_FP8=true

# 设备映射 (auto自动选择最优设备)
DEVICE_MAP=auto

# 数据类型 (auto自动选择)
TORCH_DTYPE=auto

# =============================================================================
# 生成参数配置 (非思考模式，针对CoT优化)
# =============================================================================

# 温度参数 (0.7为非思考模式推荐值)
TEMPERATURE=0.7

# Top-p参数 (0.8为非思考模式推荐值)
TOP_P=0.8

# 最大生成token数
MAX_TOKENS=2048

# =============================================================================
# 实验配置
# =============================================================================

# 最大重试次数 (本地推理通常不需要重试)
MAX_RETRIES=1

# 基础延迟时间(秒) - 本地推理无需延迟
BASE_DELAY=0

# 是否启用详细日志
VERBOSE_LOGGING=true

# =============================================================================
# 禁用的配置 (确保不使用在线API)
# =============================================================================

# 以下配置在离线模式下被忽略
# GEMINI_API_KEY=disabled_in_offline_mode
# API_KEY=disabled_in_offline_mode  
# API_BASE=disabled_in_offline_mode