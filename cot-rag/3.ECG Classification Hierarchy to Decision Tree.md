

# **A Framework for Deriving and Operationalizing Diagnostic Hierarchies from ECG Classification Models using Knowledge-Graph-Driven Decision Trees**

## **Section 1: Foundational Paradigms in Hierarchical Clinical Classification**

The accurate and timely interpretation of electrocardiograms (ECGs) is a cornerstone of modern cardiology. With the advent of deep learning, automated ECG analysis has achieved remarkable performance, often rivaling human experts in specific classification tasks. However, the predominant approach—flat classification—presents a fundamental disconnect with the cognitive processes of clinical diagnosis. In a flat classification paradigm, a model predicts a single label from a set of mutually exclusive and independent categories. This structure fails to capture the intricate, hierarchical relationships that define medical nosology. A diagnosis of "Anterior Myocardial Infarction," for instance, is not merely an alternative to "Normal Sinus Rhythm"; it is a specific subtype of the broader "Myocardial Infarction" category, which itself falls under the general heading of "Abnormal ECG." This inherent structure is a critical component of clinical reasoning, guiding the diagnostic process from general observations to specific conclusions.

The failure of flat classification models to recognize these relationships leads to two significant shortcomings. First, it results in clinically nonsensical evaluation; a model that misclassifies an "Anterior MI" as an "Inferior MI" (a confusion between two closely related subtypes) is penalized identically to a model that misclassifies it as a "Normal" rhythm—an error of far greater clinical severity.1 Second, and more critically, it produces outputs that are less interpretable and less aligned with the diagnostic workflow of a clinician, thereby hindering trust and adoption. This report outlines a comprehensive framework to bridge this gap. It details a methodology for first extracting the implicit diagnostic hierarchy learned by existing, often flat, ECG classification models, and then operationalizing this hierarchy within a novel, knowledge-graph-driven decision tree. This approach aims to transform the opaque outputs of powerful classifiers into a structured, interpretable, and clinically congruent diagnostic pathway.

### **1.1 The Clinical Imperative for Hierarchical Diagnosis**

Clinical diagnosis is rarely a single, discrete determination. Instead, it is a sequential process of inquiry and refinement, moving from broad, syndromic categories to specific etiological diagnoses. An ECG interpretation follows this pattern: a clinician might first identify the presence of a general abnormality, such as an arrhythmia. This initial finding then prompts a more detailed investigation to classify the type of arrhythmia (e.g., tachycardia vs. bradycardia), which is subsequently refined to a specific diagnosis like "Ventricular Tachycardia".2 This process is inherently hierarchical, with each step narrowing the diagnostic possibilities based on the findings of the previous step.

This cognitive workflow is formally codified in established medical taxonomies such as the International Classification of Diseases (ICD-10) and the Systematized Nomenclature of Medicine Clinical Terms (SNOMED-CT). These systems are not flat lists of codes; they are structured as deep hierarchies or directed acyclic graphs (DAGs), where specific disease codes are nested within broader categories.3 For example, the ICD-10 system organizes diagnoses into chapters based on bodily systems (e.g., "Diseases of the circulatory system"), which are then subdivided into blocks (e.g., "Ischaemic heart diseases"), and finally into specific codes (e.g., "I21.0 \- Acute transmural myocardial infarction of anterior wall"). This structure provides a standardized, globally recognized framework for clinical documentation, billing, and epidemiology, and it serves as a natural target for the output space of diagnostic AI models. By aligning a model's classification structure with these established hierarchies, we not only improve its clinical relevance but also facilitate its integration into existing healthcare information systems. The imperative, therefore, is to develop classification models that do not merely assign labels but navigate these diagnostic hierarchies in a manner that mirrors and respects the logic of clinical practice.

### **1.2 A Survey of Hierarchical Classification (HC) Methodologies**

To address the limitations of flat classification, the field of machine learning has developed a specialized sub-discipline known as Hierarchical Classification (HC). HC methods are designed to handle classification problems where the class labels are organized in a hierarchy, typically represented as a tree or a Directed Acyclic Graph (DAG).5 In a tree structure, each class (except the root) has exactly one parent, whereas in a DAG, a class can have multiple parents, allowing for more complex relationships (e.g., a condition that belongs to both an infectious and a respiratory disease category).7 The core objective of HC is to leverage this hierarchical structure to improve classification accuracy and produce predictions that are consistent with the predefined class relationships (i.e., if a sample is classified into a child class, it must also belong to its parent class).

HC methodologies are broadly categorized into two primary strategies: local classifiers and global classifiers.5

* **Local Classifiers (Top-Down Approach):** This strategy decomposes the complex hierarchical problem into a set of simpler, smaller classification problems distributed across the hierarchy. A common implementation involves training one classifier for each internal node of the hierarchy. During prediction, an input sample starts at the root and is passed down the tree; at each node, the local classifier determines which child node the sample should be passed to next, until a leaf node is reached.8 For instance, a top-level classifier might first distinguish between "Normal" and "Disease." If "Disease" is predicted, the sample is then passed to a second-level classifier that specializes in distinguishing between different disease subtypes.9 This approach is modular and can effectively handle large hierarchies, but it is susceptible to "error propagation" or "cascading errors," where a misclassification at a high level of the tree cannot be corrected at lower levels.  
* **Global Classifiers (Big-Bang Approach):** In contrast, the global classifier approach attempts to solve the entire hierarchical problem with a single, complex model. This is typically achieved by designing a model that considers the full class hierarchy during the training process. The model's architecture or, more commonly, its loss function is modified to account for the hierarchical relationships between labels.5 For example, the loss function can be designed to penalize errors between distant classes in the hierarchy more heavily than errors between closely related classes (e.g., siblings or parent-child pairs). This approach can potentially lead to higher accuracy by leveraging information across the entire hierarchy simultaneously, but it is often more computationally complex and less straightforward to implement than local classifier methods.

Furthermore, many real-world medical scenarios involve **multi-label hierarchical classification**, where a single patient case (or ECG) can be associated with multiple diagnoses that may reside in different branches of the hierarchy. For example, a patient could simultaneously have "Atrial Fibrillation" and an "Old Myocardial Infarction." In this context, the task is to predict a set of labels for each instance, with the constraint that the predicted set must be hierarchically consistent.10

### **1.3 State-of-the-Art Hierarchical Models in Medical AI**

The principles of hierarchical classification have been successfully applied to various domains within medical AI, yielding models that are more accurate and interpretable than their flat counterparts. These applications provide a strong precedent for the framework proposed in this report.

One of the most well-developed areas is in **medical imaging**. The Hierarchical Medical Image Classification (HMIC) approach, for example, utilizes a stack of deep convolutional neural networks (CNNs) to analyze histopathology images.14 In this architecture, a "parent-level" model is first trained to classify images into broad categories (e.g., Celiac Disease, Environmental Enteropathy, Normal). The outputs of this model are then used to route the image to a specialized "child-level" model, which performs a finer-grained classification within the predicted parent category (e.g., classifying the severity of Celiac Disease). This top-down, stacked approach directly mirrors the structure of the diagnostic problem and has been shown to outperform flat multi-class models, especially when dealing with class imbalance.14

In the specific domain of **ECG arrhythmia classification**, several hierarchical approaches have demonstrated significant promise. Some models are designed around clinical concepts like severity, creating a hierarchy where the top levels classify the urgency of a condition, while lower levels identify the specific arrhythmia type, providing a more actionable output for both patients and clinicians.15 A particularly innovative approach involves adapting the Hierarchical Attention Network (HAN), a model originally designed for natural language processing, to the ECG domain.16 This adaptation treats the 1D ECG signal as a hierarchical structure composed of waves, which form heartbeats, which in turn form windows or sequences of beats.16 The HAN model uses attention mechanisms at each level to learn which parts of the signal are most important for the final classification. For example, it can learn which specific waves are most indicative of a particular heartbeat type, and which heartbeats in a sequence are most critical for the overall arrhythmia diagnosis. This not only provides a hierarchical classification but also enhances interpretability by highlighting the evidential basis for the model's decision within the signal itself. The success of these diverse hierarchical models in medicine underscores a clear trend: structuring AI models to reflect the inherent hierarchy of the clinical problem domain is a powerful strategy for improving both performance and clinical utility.

The following table provides a comparative overview of key hierarchical architectures relevant to medical classification, highlighting their core mechanisms and suitability for the subsequent task of hierarchy extraction.

| Model Name | Hierarchical Approach | Granularity | Suitability for Hierarchy Extraction | Key Reference(s) |
| :---- | :---- | :---- | :---- | :---- |
| **HMIC (Hierarchical Medical Image Classification)** | Stacked CNNs (Local Classifiers) | Disease / Subtype | High | 14 |
| **HAN-ECG (Hierarchical Attention Network for ECG)** | Hierarchical Attention Layers | Sequence / Segment / Wave | High | 16 |
| **Severity-Based ECG Classifier** | Top-Down Decision Logic | Urgency / Arrhythmia Type | High | 15 |
| **Global HMC Models** | Single Model with Hierarchical Loss | Full Label Space | Medium | 5 |

## **Section 2: Methodologies for Extracting Implicit Hierarchies from ECG Classifiers**

While designing a model that is hierarchical by nature is a valid approach, a more common and practical scenario involves starting with powerful, pre-trained classification models that were designed with a flat output space. These models, such as deep residual networks (ResNets) or Squeeze-and-Excitation Networks (SE-Nets), often achieve state-of-the-art performance but produce a simple vector of probabilities, treating each diagnostic class as an independent entity.18 The central challenge, and the focus of this section, is to develop methodologies for reverse-engineering the diagnostic hierarchy that such a model has

*implicitly* learned through its training. This process is one of knowledge discovery—of interrogating the model to reveal its internal conceptual structure. The resulting hierarchy is not a universal clinical truth, but rather a model-specific artifact that represents how that particular model organizes its understanding of cardiac pathologies.

This extraction process serves a dual purpose. Primarily, it provides the structural backbone for the decision tree framework detailed in the subsequent sections. Secondarily, it functions as a powerful new tool for model auditing and explainable AI (XAI). By visualizing the model's learned hierarchy, a clinician can perform a "sanity check." If the derived structure is clinically nonsensical—for example, if it suggests that "Normal Sinus Rhythm" is a subtype of "Myocardial Infarction"—it provides immediate, clear evidence of a fundamental flaw in the model's learning process, regardless of its reported accuracy metrics. This offers a qualitative, conceptual evaluation that goes beyond traditional performance scores, addressing the critical need for trust and transparency in medical AI.20

### **2.1 Output-Based Derivation: Mining the Label Space**

The most direct way to infer a model's learned relationships is to analyze its predictions over a large and diverse dataset. By treating the model's outputs not as final answers but as a rich source of statistical information, we can mine the label space to uncover consistent patterns that imply a hierarchical structure.

* **Statistical Co-occurrence Analysis:** For multi-label classification models, where multiple diagnoses can be predicted for a single ECG, a straightforward approach is to analyze the co-occurrence frequency of labels. If two labels, A and B, frequently appear together in predictions, it suggests a relationship. This can be extended to infer parent-child relationships. For instance, if label B (e.g., "Atrial Fibrillation") almost never appears without label A (e.g., "Irregular Rhythm"), but A often appears without B, it strongly suggests that B is a subtype of A.11 This method transforms the problem of hierarchy discovery into one of mining frequent itemsets and association rules from the model's prediction corpus.  
* **Conditional Probability Analysis:** A more formal and powerful method involves analyzing the conditional probabilities of the model's outputs. To test the hypothesis that class B is a child of class A, one can compute the model's predicted probability P(B∣A) across a validation set. If the model consistently assigns a high probability to B *only when* it also assigns a high probability to A, a hierarchical dependency is indicated. For example, if the average predicted probability of P("Anterior MI") is low when P("Myocardial Infarction") is low, but high when P("Myocardial Infarction") is high, this supports the relationship Myocardial Infarction \-\> Anterior MI. This method allows for the construction of a directed graph where edges represent strong conditional dependencies, which can then be pruned to form a tree or DAG structure.  
* **Semantic Mapping to Ontologies:** A highly effective and clinically grounded approach is to leverage existing medical knowledge. The output labels of the classification model (e.g., "AFIB," "SBRAD," "1AVB") can be mapped to corresponding concepts in a standardized medical ontology like ICD-10 or SNOMED-CT.3 Once this mapping is established, the hierarchical relationships are simply inherited from the ontology's predefined structure. For example, if the model outputs labels for "Atrial Fibrillation" and "Atrial Flutter," and both of these map to concepts that are children of "Supraventricular Arrhythmias" in the ontology, then that hierarchical relationship is adopted for the model's label space. This method has the significant advantage of ensuring that the derived hierarchy is clinically valid and uses standard terminology. A hybrid approach, where statistical methods are used to propose relationships that are then validated or pruned against a medical ontology, is likely the most robust strategy.

### **2.2 Architecture-Based Derivation: Deconstructing Hierarchical Models**

In cases where the ECG classification model is not a simple flat classifier but has some inherent hierarchical structure, the hierarchy can often be extracted directly from the model's architecture. This approach is less about discovery and more about direct translation of the model's design into a formal graph structure.

* **Decomposing Stacked Classifiers:** For models that explicitly follow a top-down, local classifier approach, such as the HMIC framework adapted for ECGs, the hierarchy is self-evident.14 The architecture itself defines the hierarchy: the parent-level model's output classes are the parent nodes, and the child-level models they trigger correspond to the child nodes. The connections between these models directly map to the edges of the hierarchical tree. Extracting the hierarchy in this case is a matter of documenting the model's information flow.  
* **Interpreting Hierarchical Attention Networks (HAN):** For more complex models like the HAN adapted for ECG analysis, the hierarchy is defined by the structure of the data representation and the flow of attention.16 The model processes the ECG signal at multiple levels of granularity—for example, a "segment" level and a "sequence" level, where sequences are composed of segments.16 The attention mechanism at the higher level (sequence) learns to assign weights to the outputs of the lower level (segments), indicating which segments were most influential in making the final sequence-level classification. This provides a functional hierarchy of evidence. The extracted hierarchy would represent which lower-level features (e.g., specific beat morphologies captured in segments) are considered by the model as evidence for higher-level diagnoses (e.g., a specific arrhythmia). This method reveals a hierarchy of  
  *importance* rather than a simple "IS-A" relationship, providing a deeper level of insight into the model's decision-making process.

## **Section 3: Structuring the Diagnostic Pathway: From Hierarchy to a Knowledge-Graph-Informed Decision Tree**

Once the implicit diagnostic hierarchy has been extracted from the ECG classification model(s), the next critical step is to transform this abstract structure into an operational framework. A decision tree provides a natural and intuitive representation for a hierarchical diagnostic pathway.22 However, a standard decision tree, with its simple, brittle rules, is insufficient to capture the complexity and uncertainty inherent in medical diagnosis. To address this, this report proposes a novel approach that augments the traditional decision tree structure with the rich, relational framework of a knowledge graph (KG). This is inspired by the CoT-RAG (Chain-of-Thought Retrieval-Augmented Generation) framework, which uses KGs to modulate and enhance the reasoning processes of large language models.24 By adapting this concept, we transform each node in the decision tree from a simple conditional split into a structured KG entity, creating a flexible, interpretable, and powerful reasoning graph.

This fusion of a decision tree structure with a KG schema offers significant advantages. A conventional decision tree hard-codes its logic, making it difficult to update or modify without retraining. In contrast, by separating the *structure* of the diagnostic flow (the tree's branches) from the *logic* of the decisions (the attributes within the KG nodes), the system becomes highly modular and maintainable.24 A clinician or an automated validation system could potentially adjust a decision threshold or swap an underlying classifier by simply updating an attribute in the KG, without re-engineering the entire system. This transforms the diagnostic tool from a rigid "black box" into a more transparent and adaptable "glass box," a crucial step toward building trust and facilitating clinical collaboration.

### **3.1 Mapping the Diagnostic Hierarchy to a Decision Tree Structure**

The translation from the derived hierarchy to the basic decision tree structure is a direct mapping process. The hierarchical relationships discovered in the previous section form the blueprint for the tree's topology.

* **Root and Internal Nodes:** The most general categories from the top of the derived hierarchy become the root and internal nodes of the decision tree. Each of these nodes represents a major decision point in the diagnostic pathway. For example, the root node might correspond to the question "Is the ECG normal or abnormal?" Subsequent internal nodes would then address more specific classifications, such as "Is an arrhythmia present?" or "Is there evidence of ischemia?".22  
* **Leaf Nodes:** The most specific diagnoses, which reside at the terminal points of the hierarchy, map directly to the leaf nodes of the decision tree. These nodes represent the final outputs of the diagnostic process, such as "Atrial Fibrillation," "First-Degree AV Block," or "Anterior Myocardial Infarction".22 Reaching a leaf node signifies the conclusion of a diagnostic path.  
* **Branches:** The parent-child links established in the hierarchy define the branches or edges of the decision tree. Each branch represents the outcome of a decision made at an internal node, guiding the traversal to the next, more specific diagnostic question. For example, from the "Is an arrhythmia present?" node, a "Yes" branch would lead to further nodes for classifying the type of arrhythmia, while a "No" branch might lead to nodes for assessing morphological abnormalities.

### **3.2 Augmenting Tree Nodes with a Knowledge Graph Framework (CoT-RAG Adaptation)**

The core innovation of this framework lies in treating each node of the decision tree not as a simple rule, but as a rich, structured entity within a knowledge graph. This approach provides a formal, standardized way to encode the logic, data requirements, and contextual information needed at each step of the diagnostic process. Each node becomes a self-contained module that explicitly declares its function and its relationship to other nodes and to the underlying classification models.

The proposed schema for each KG node entity is designed to be comprehensive and extensible:

* **Node\_ID**: A unique identifier for the node (e.g., N01\_Rhythm\_Assessment). This is essential for unambiguous referencing within the graph.  
* **Diagnosis\_Class**: The specific clinical concept or question being evaluated at this node (e.g., "General Arrhythmia," "Atrial Fibrillation," "Myocardial Infarction").  
* **Parent\_Node**: A pointer to the Node\_ID of the parent node, explicitly defining the hierarchical structure and the path taken to reach this point.  
* **Child\_Nodes**: A list of pointers to the Node\_IDs of potential subsequent nodes, defining the possible outcomes of the decision made at this node.  
* **Decision\_Rule\_Logic**: The operational core of the node. This is not a simple threshold but a pseudo-programmatic rule that specifies how to make the branching decision. This rule directly references the outputs of the underlying ECG classifiers. For example: IF get\_prob('Arrhythmia\_Model', 'AFIB') \> 0.7 AND get\_prob('Rhythm\_Model', 'Irregular') \> 0.9 THEN GOTO 'N05\_Confirm\_AFIB' ELSE GOTO 'N06\_Other\_Irregular\_Rhythm'. This pseudo-programmatic representation, inspired by the "Pseudo-Program Prompting" concept, provides a clear, logical, and executable specification for the decision process, enhancing rigor and reducing the ambiguity of natural language rules.24  
* **Required\_Classifier\_Inputs**: An explicit declaration of the data needed to execute the Decision\_Rule\_Logic. This attribute lists the specific classification model(s) and the output class(es) that must be queried. For example: \`\`. This design natively supports the use of multi-classifier ensembles, allowing the decision tree to act as a high-level "conductor" that orchestrates a suite of specialized models. One node might rely on a model optimized for arrhythmia detection, while another might use a different model optimized for ischemia classification.  
* **Evidence\_Source**: An optional but powerful attribute for enhancing explainability. If the underlying model provides feature importance or attention weights (e.g., from a HAN model), this attribute can store pointers to the specific ECG leads, time segments, or morphological features that the model found most indicative for this Diagnosis\_Class. This provides a direct link from the high-level decision to the low-level signal data.

The following table illustrates how the components of a clinical diagnostic hierarchy are systematically mapped into the components of this KG-informed decision tree structure.

| Hierarchical Level | Corresponding Decision Tree Component | Example KG Node Attributes |
| :---- | :---- | :---- |
| **Superclass** (e.g., Rhythm Disorder) | **Root / Internal Node** | Node\_ID: N01\_Rhythm\_Check Diagnosis\_Class: "Rhythm Disorder" Decision\_Rule\_Logic: IF get\_prob('Model\_A', 'Arrhythmia') \> 0.5 THEN 'N02\_Tachy\_Brady\_Check' ELSE 'N03\_Morphology\_Check' |
| **Class** (e.g., Tachyarrhythmia) | **Internal Node** | Node\_ID: N02\_Tachy\_Brady\_Check Diagnosis\_Class: "Tachyarrhythmia" Decision\_Rule\_Logic: IF get\_prob('Model\_A', 'Tachycardia') \> 0.8 THEN 'N04\_AFIB\_Check' ELSE 'N07\_Brady\_Check' |
| **Subclass** (e.g., Atrial Fibrillation) | **Leaf Node** | Node\_ID: L01\_Atrial\_Fibrillation Diagnosis\_Class: "Atrial Fibrillation" Decision\_Rule\_Logic: FINAL\_DIAGNOSIS |

## **Section 4: Operationalizing the Decision Tree: A Classifier-Driven Traversal Mechanism**

With the diagnostic hierarchy structured as a knowledge-graph-informed decision tree, the system is ready for operation. The traversal mechanism defines the runtime behavior of the framework, detailing how a new ECG signal is processed to yield a final diagnosis and an accompanying explanatory path. This process is entirely data-driven, with the navigation through the tree's branches being controlled at each step by the real-time outputs of the underlying ECG classification models. The sequence of nodes visited during this traversal forms an explicit "chain of thought," providing a step-by-step, evidence-based justification for the final diagnostic conclusion.24 This inherent traceability is a cornerstone of the framework's approach to explainable AI, transforming the classification process from a single, opaque prediction into a transparent and auditable sequence of logical inferences.

### **4.1 Formulating Decision Rules from Classifier Outputs**

The Decision\_Rule\_Logic stored within each KG node is the engine of the traversal process. These rules must be carefully formulated to translate the continuous outputs of deep learning models into discrete branching decisions.

* **Using Posterior Probabilities:** The most common and intuitive method is to base decisions on the posterior probabilities (i.e., the softmax outputs) of the classification models. A typical rule would compare the probability of a specific class against a predefined threshold: for example, IF P(Myocardial\_Infarction) \> 0.9. This approach is simple to implement and easy to interpret.  
* **Using Logits or Other Activations:** In some cases, using the pre-softmax activation values (logits) may provide more granular control. Logits are not constrained to the range and can sometimes offer better separation between classes, especially in cases of high uncertainty where probabilities may cluster around the decision boundary.  
* **Handling Multi-Label and Multi-Class Inputs:** The rule engine must be capable of handling complex logical conditions. For instance, a decision might require the simultaneous presence of multiple findings, which can be implemented with a logical AND operator (e.g., IF P(ST\_Elevation) \> 0.8 AND P(Reciprocal\_ST\_Depression) \> 0.7). Conversely, a decision might be triggered by any one of a group of related findings, using a logical OR operator (e.g., IF P(PVC) \> 0.6 OR P(PAC) \> 0.6).  
* **Threshold Determination:** The selection of appropriate probability thresholds is a critical step that directly impacts the sensitivity and specificity of the diagnostic pathway. These thresholds can be determined through several methods:  
  * **Validation Set Optimization:** Standard optimization techniques can be used to find thresholds that maximize a chosen performance metric (e.g., F1-score, Matthews correlation coefficient) on a held-out validation dataset.  
  * **ROC Curve Analysis:** Analyzing the Receiver Operating Characteristic (ROC) curve for a given classifier output allows for the selection of a threshold that provides a desired trade-off between the true positive rate (sensitivity) and the false positive rate (1-specificity).  
  * **Clinical Risk Stratification:** In a clinical context, thresholds may be set based on the risk tolerance for a particular condition. For life-threatening diagnoses (e.g., Ventricular Tachycardia), a lower threshold might be chosen to maximize sensitivity, accepting a higher false positive rate to ensure that potential cases are not missed.

### **4.2 The Traversal Algorithm**

The algorithm for processing a single ECG and traversing the tree is a deterministic, sequential process:

1. **Initialization:** A new ECG signal is provided as input. It is pre-processed and fed into all the necessary base classification models that are referenced in the decision tree's KG. The complete set of outputs (e.g., probability vectors) from all models is computed and stored in a readily accessible data structure.  
2. **Start at Root:** The traversal process begins at the designated root node of the decision tree. A variable, current\_node, is initialized to the root node's Node\_ID. A list or stack, decision\_path, is initialized to store the sequence of visited nodes.  
3. **Node Evaluation:** At the current\_node, the system retrieves the Decision\_Rule\_Logic and Required\_Classifier\_Inputs from its corresponding KG entity.  
4. **Execute Rule:** The Decision\_Rule\_Logic is executed. The rule engine fetches the required classifier outputs (which were pre-computed in Step 1\) and evaluates the logical expression.  
5. **Branch Selection:** The boolean outcome of the rule evaluation determines which branch to follow. The current\_node is updated to the Node\_ID of the appropriate child node as specified in the Child\_Nodes attribute. The new current\_node's ID is appended to the decision\_path.  
6. **Iteration:** Steps 3 through 5 are repeated, with the system moving from parent to child through the tree, guided at each step by the classifier outputs.  
7. **Termination and Output:** The loop continues until the current\_node is a leaf node (i.e., a node with no children). At this point, the traversal is complete. The final system output consists of two components:  
   * **Final Diagnosis:** The Diagnosis\_Class associated with the terminal leaf node.  
   * **Decision Path:** The ordered list of Node\_IDs stored in decision\_path, which represents the complete reasoning chain that led to the final diagnosis.

### **4.3 Handling Uncertainty and Ambiguity**

A robust clinical decision support system must gracefully handle cases where the model outputs are not definitive. The KG-driven framework allows for the explicit definition of strategies to manage uncertainty.

* **Low-Confidence Pathways:** Decision rules can be designed with "gray zones." For example, if a classifier's probability for a critical condition is neither definitively high nor low (e.g., 0.4 \< P(Condition) \< 0.6), the rule can direct the traversal to a special "Uncertain" or "Requires Review" leaf node. This prevents the system from making a confident assertion based on weak evidence and instead flags the case for human review.  
* **Conflicting Information:** When using an ensemble of models, the outputs may sometimes conflict. The Decision\_Rule\_Logic can be designed with fallback or tie-breaking rules. For instance, if two models disagree on a diagnosis, the rule could prioritize the model with a historically higher F1-score for that specific diagnostic distinction. Alternatively, a conflict could trigger a path to an "Ambiguous Findings" node, again prompting human intervention. This explicit handling of ambiguity is a key feature for ensuring the safety and reliability of the system in a clinical setting.

## **Section 5: Comprehensive Evaluation and Generation of Interpretable Narratives**

The final stages of the framework development involve rigorous validation of the system's performance and the translation of its logical outputs into a format that is meaningful and useful for a human clinician. The evaluation of a hierarchical system demands specialized metrics that go beyond standard classification accuracy, as it is crucial to assess not only the correctness of the final label but also the validity of the entire diagnostic path. Similarly, the final output should not be a mere diagnostic code but a comprehensive narrative that explains the "why" behind the conclusion. This narrative generation closes the loop on explainability, transforming the system's internal chain of reasoning into a transparent, human-readable report that can foster clinical trust and facilitate safe, effective integration into medical workflows.21

### **5.1 The Inadequacy of Flat Metrics**

Applying traditional, flat evaluation metrics to a hierarchical classification system can be profoundly misleading. A standard accuracy score, for example, treats all misclassifications as equally severe. This is clinically inappropriate. Consider a hierarchy where "Myocardial Infarction" is a parent to "Anterior MI" and "Inferior MI." A system that incorrectly classifies an "Anterior MI" as an "Inferior MI" has made an error, but it has correctly identified the presence of the life-threatening parent condition. In contrast, a system that classifies the same "Anterior MI" as "Normal Sinus Rhythm" has made a catastrophic error. A flat accuracy metric would penalize both of these errors equally, failing to capture the vast difference in their clinical severity and providing a distorted view of the system's true performance.1 Therefore, adopting evaluation metrics that are inherently aware of the hierarchical structure is not just a methodological preference but a prerequisite for responsible and meaningful assessment.

### **5.2 Advanced Evaluation for Hierarchical Systems**

To properly evaluate the performance of the KG-driven decision tree, it is essential to employ metrics designed specifically for hierarchical classification tasks. These metrics assess correctness by considering the relationships between the predicted and true labels within the context of the class hierarchy.

* **Hierarchical Precision, Recall, and F-Score:** These are among the most widely used set-based measures for HC. To calculate them, the set of predicted labels and the set of true labels for a given sample are first "augmented" by adding all of their respective ancestors in the hierarchy, up to the root.  
  * Let Y be the set of true labels and Y^ be the set of predicted labels.  
  * Let Yaug​ and Y^aug​ be the ancestor-augmented sets.  
  * Hierarchical Precision (PH​) is the size of the intersection of these augmented sets divided by the size of the predicted augmented set:

    PH​=∣Y^aug​∣∣Yaug​∩Y^aug​∣​  
  * Hierarchical Recall (RH​) is the size of the intersection divided by the size of the true augmented set:

    RH​=∣Yaug​∣∣Yaug​∩Y^aug​∣​

    These metrics correctly penalize errors made high up in the hierarchy more severely. In the previous example, the intersection between the augmented sets for "Anterior MI" and "Inferior MI" would be large (as they share the "Myocardial Infarction" ancestor), resulting in high precision and recall. Conversely, the intersection between "Anterior MI" and "Normal Sinus Rhythm" would be small or empty, leading to low scores.1  
* **The Hierarchical Confusion Matrix:** A more recent and powerful concept is the hierarchical confusion matrix. This approach redefines the fundamental concepts of True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN) in the context of a hierarchical path.26 For a given prediction, the elements are calculated based on the nodes along the true path and the predicted path:  
  * **Hierarchical True Positives (TPH​):** The number of nodes correctly included in the predicted path (i.e., nodes present in both the true and predicted paths).  
  * **Hierarchical False Positives (FPH​):** The number of nodes incorrectly included in the predicted path (i.e., nodes in the predicted path but not the true path).  
  * **Hierarchical False Negatives (FNH​):** The number of nodes that were in the true path but were missed by the predicted path.  
  * Hierarchical True Negatives (TNH​): The number of nodes correctly excluded from the predicted path.  
    By summing these values across a test set, a single hierarchical confusion matrix can be constructed. From this matrix, all standard classification metrics (Accuracy, Precision, Recall, F1-Score, etc.) can be calculated, but now in a way that is fully aware of the hierarchical structure of the problem.26

The following table provides a conceptual framework for contrasting flat and hierarchical evaluation metrics, highlighting their definitions and appropriate interpretations.

| Metric | Flat Definition/Formula | Hierarchical Definition/Formula | When to Use & Interpretation |
| :---- | :---- | :---- | :---- |
| **Accuracy** | TP+TN+FP+FNTP+TN​ | TPH​+TNH​+FPH​+FNH​TPH​+TNH​​ | **Flat:** Use for balanced, non-hierarchical problems. **Hierarchical:** Provides an overall measure of path correctness, accounting for all correct and incorrect node decisions in the hierarchy. |
| **Precision** | TP+FPTP​ | TPH​+FPH​TPH​​ | **Flat:** Measures correctness of positive predictions. **Hierarchical:** Measures the proportion of predicted path nodes that were correct. High PH​ means the predicted path has few incorrect steps. |
| **Recall** | TP+FNTP​ | TPH​+FNH​TPH​​ | **Flat:** Measures coverage of actual positives. **Hierarchical:** Measures the proportion of the true path that was correctly identified. High RH​ means the predicted path did not miss many necessary steps. |
| **F1-Score** | 2⋅Precision+RecallPrecision⋅Recall​ | 2⋅PH​+RH​PH​⋅RH​​ | **Flat:** Harmonic mean of precision and recall. **Hierarchical:** Provides a balanced measure of the overall quality of the predicted diagnostic path. |

### **5.3 From Decision Path to Diagnostic Narrative**

The ultimate goal of an explainable AI system is to communicate its findings effectively to a human user. The decision path generated by the traversal algorithm provides the logical "scaffolding" for this explanation. The final step is to translate this structured path into a fluid, natural language diagnostic narrative.

* **Template-Based Narrative Generation:** A robust and controllable method for narrative generation is to use predefined text templates. Each node in the knowledge graph can be associated with a narrative template string. This template can contain placeholders for dynamic values that are filled in at runtime, such as the classifier probabilities that triggered the decision at that node.  
  * *Example Template for an Internal Node:* "The analysis next considered the possibility of {Diagnosis\_Class}. The relevant classifier yielded a confidence score of {probability}, which is {above/below} the threshold for this condition. Therefore, the pathway proceeds to evaluate {next\_diagnosis\_class}."  
  * *Example Template for a Leaf Node:* "Based on the preceding findings, the traversal concluded at this node. The final inferred diagnosis is **{Diagnosis\_Class}**."  
* **Assembling the Narrative:** As the decision tree is traversed for a given ECG, the system collects the narrative template from each visited node. It populates the placeholders in each template with the relevant runtime data (e.g., specific probability values). The populated text snippets are then concatenated in the order of traversal.  
* **Leveraging NLP for Fluency:** The resulting sequence of sentences can be further refined using basic Natural Language Generation (NLG) techniques to improve its coherence and readability. This could involve adding transition words, ensuring correct grammar, and structuring the output into a well-formed paragraph. This process transforms the discrete, logical steps of the decision path into a cohesive story that explains not just *what* the diagnosis is, but *why* the system arrived at that conclusion, effectively closing the loop on explainability.27

## **Section 6: Synthesis, Implementation Strategy, and Future Directions**

This report has detailed a comprehensive, end-to-end framework for transforming the outputs of standard ECG classification models into an interpretable, clinically aligned diagnostic pathway. The methodology begins by extracting the implicit hierarchical relationships learned by the classifiers, formalizes this structure into a knowledge-graph-augmented decision tree, and operationalizes it through a classifier-driven traversal mechanism. The final output is not merely a label but a full diagnostic narrative, justified at each step by model-derived evidence and evaluated by metrics appropriate for the hierarchical nature of the task. This approach represents a significant step toward creating AI systems in cardiology that are not only accurate but also transparent, auditable, and trustworthy.

### **6.1 Synthesis of the End-to-End Framework**

The complete workflow can be visualized as a multi-stage pipeline:

1. **Input & Parallel Classification:** A raw ECG signal is fed into a suite of pre-trained classification models (e.g., one for arrhythmias, one for ischemia, one for morphology).  
2. **Hierarchy Extraction (Offline):** Using the output-based and architecture-based methods described in Section 2, a diagnostic hierarchy is derived. This is a one-time, offline process for a given set of models.  
3. **KG-Driven Decision Tree Construction (Offline):** The derived hierarchy is mapped to a decision tree structure, where each node is defined as a rich entity within a knowledge graph, complete with decision logic and data requirements, as detailed in Section 3\.  
4. **Classifier-Driven Traversal (Online):** For the input ECG, the system executes the traversal algorithm from Section 4, navigating the tree from the root to a leaf node based on the real-time outputs of the classifiers. This generates a decision path.  
5. **Narrative Generation & Output:** The sequence of nodes in the decision path is used to assemble a natural language report, as described in Section 5, which is presented to the user as the final, explainable output.

The primary advantages of this synthesized framework are its modularity, which allows for the independent updating of classifiers or decision rules; its enhanced interpretability, stemming from the explicit chain-of-thought reasoning; its alignment with clinical diagnostic workflows; and its ability to leverage the power of existing, high-performance classification models within a more structured and transparent system.

### **6.2 Implementation Strategy and Challenges**

The implementation of this framework can be achieved using a combination of standard data science and software engineering tools.

* **Recommended Tooling:** Python is the natural language of choice for this framework.  
  * **Base Classifiers:** Models can be built or loaded using established deep learning libraries like PyTorch or TensorFlow.  
  * **Decision Tree & KG:** The graph structure can be effectively managed using libraries like NetworkX, which is well-suited for creating and manipulating complex graph structures like the proposed KG-augmented tree.  
  * **Traversal & Rule Engine:** The traversal algorithm and rule engine can be implemented with standard Python logic.  
  * **Narrative Generation:** Simple string formatting can suffice for the template-based approach, while more advanced NLG could leverage libraries like NLTK or spaCy.30

Despite the availability of tools, several significant challenges must be anticipated:

* **Cascading Errors:** As with any top-down hierarchical approach, errors made at high-level nodes can propagate and lead to entirely incorrect diagnostic paths. Robust uncertainty handling and the potential for exploring multiple paths in low-confidence scenarios are critical mitigation strategies.  
* **Scalability and Maintenance:** As the number of diagnostic classes grows, the complexity of the KG and the number of decision rules can become difficult to manage. A well-designed schema and potentially automated tools for rule validation will be necessary for maintaining a large-scale system.  
* **Data Scarcity for Rare Diseases:** Deriving statistically significant hierarchical relationships for rare cardiac conditions will be challenging due to the limited number of examples in most datasets. This may necessitate a greater reliance on expert knowledge and ontology mapping for the less common branches of the hierarchy.

### **6.3 Future Research Directions**

This framework provides a solid foundation for numerous avenues of future research aimed at creating more intelligent, autonomous, and collaborative diagnostic AI.

* **Dynamic Rule Learning:** A significant advancement would be to move from manually defined or validation-set-optimized decision rules to a system that learns the optimal rules and thresholds directly. Reinforcement learning could be explored, where an agent is trained to navigate the decision tree, receiving rewards based on the accuracy and efficiency of the final diagnosis.  
* **Incorporating Clinical Feedback Loops:** A truly adaptive system would be able to learn from its mistakes. Future work could focus on designing mechanisms where a clinician's feedback—for instance, correcting an erroneous narrative or disagreeing with a diagnostic path—is used to automatically update the attributes of the KG nodes. This could involve adjusting probability thresholds or even modifying the structure of the tree itself, enabling the system to continuously improve through interaction with experts.  
* **Integration with Generative Large Language Models (LLMs):** While the proposed template-based narrative generation is robust and safe, the power of modern LLMs offers a path toward far more sophisticated and context-aware reporting. The decision path and the rich data within the visited KG nodes could be provided as a structured prompt to an LLM. The LLM could then be tasked with generating a high-quality, nuanced diagnostic summary that not only recounts the decision steps but also synthesizes the findings, discusses potential differential diagnoses, and tailors the language to the specific clinical context, moving the system from a simple reporter to a true diagnostic assistant.

#### **引用的著作**

1. Evaluation Measures for Hierarchical Classification: a unified view and novel approaches, 访问时间为 八月 18, 2025， [https://www.researchgate.net/publication/243458423\_Evaluation\_Measures\_for\_Hierarchical\_Classification\_a\_unified\_view\_and\_novel\_approaches](https://www.researchgate.net/publication/243458423_Evaluation_Measures_for_Hierarchical_Classification_a_unified_view_and_novel_approaches)  
2. Cardiac arrhythmia classification using hierarchical classification model | Request PDF, 访问时间为 八月 18, 2025， [https://www.researchgate.net/publication/262206114\_Cardiac\_arrhythmia\_classification\_using\_hierarchical\_classification\_model](https://www.researchgate.net/publication/262206114_Cardiac_arrhythmia_classification_using_hierarchical_classification_model)  
3. Diagnosis Prediction over Patient Data using Hierarchical Medical Taxonomies \- Aalborg Universitets forskningsportal, 访问时间为 八月 18, 2025， [https://vbn.aau.dk/files/612900894/HeDAI\_2023\_paper400.pdf](https://vbn.aau.dk/files/612900894/HeDAI_2023_paper400.pdf)  
4. Evaluating Hierarchical Clinical Document Classification Using Reasoning-Based LLMs, 访问时间为 八月 18, 2025， [https://www.researchgate.net/publication/393478250\_Evaluating\_Hierarchical\_Clinical\_Document\_Classification\_Using\_Reasoning-Based\_LLMs](https://www.researchgate.net/publication/393478250_Evaluating_Hierarchical_Clinical_Document_Classification_Using_Reasoning-Based_LLMs)  
5. (PDF) A survey of hierarchical classification across different ..., 访问时间为 八月 18, 2025， [https://www.researchgate.net/publication/225716424\_A\_survey\_of\_hierarchical\_classification\_across\_different\_application\_domains](https://www.researchgate.net/publication/225716424_A_survey_of_hierarchical_classification_across_different_application_domains)  
6. A Survey of Hierarchical Classification \- Across Different Application Domains \- School of Computing, 访问时间为 八月 18, 2025， [https://www.cs.kent.ac.uk/people/staff/aaf/pub\_papers.dir/DMKD-J-2010-Silla.pdf](https://www.cs.kent.ac.uk/people/staff/aaf/pub_papers.dir/DMKD-J-2010-Silla.pdf)  
7. microsoft/dstoolkit-hierarchical-multilabel-classification \- GitHub, 访问时间为 八月 18, 2025， [https://github.com/microsoft/dstoolkit-hierarchical-multilabel-classification](https://github.com/microsoft/dstoolkit-hierarchical-multilabel-classification)  
8. A Review of Performance Evaluation Measures for Hierarchical Classifiers \- AAAI, 访问时间为 八月 18, 2025， [https://cdn.aaai.org/Workshops/2007/WS-07-05/WS07-05-001.pdf](https://cdn.aaai.org/Workshops/2007/WS-07-05/WS07-05-001.pdf)  
9. (PDF) Hierarchical deep learning models using transfer learning for disease detection and classification based on small number of medical images \- ResearchGate, 访问时间为 八月 18, 2025， [https://www.researchgate.net/publication/349707612\_Hierarchical\_deep\_learning\_models\_using\_transfer\_learning\_for\_disease\_detection\_and\_classification\_based\_on\_small\_number\_of\_medical\_images](https://www.researchgate.net/publication/349707612_Hierarchical_deep_learning_models_using_transfer_learning_for_disease_detection_and_classification_based_on_small_number_of_medical_images)  
10. Coherent Hierarchical Multi-Label Classification Networks, 访问时间为 八月 18, 2025， [https://proceedings.neurips.cc/paper/2020/file/6dd4e10e3296fa63738371ec0d5df818-Paper.pdf](https://proceedings.neurips.cc/paper/2020/file/6dd4e10e3296fa63738371ec0d5df818-Paper.pdf)  
11. (PDF) A multi-label classification approach via hierarchical multi-label classification \- ResearchGate, 访问时间为 八月 18, 2025， [https://www.researchgate.net/publication/362922339\_A\_multi-label\_classification\_approach\_via\_hierarchical\_multi-label\_classification](https://www.researchgate.net/publication/362922339_A_multi-label_classification_approach_via_hierarchical_multi-label_classification)  
12. Hierarchical Multi-Label Classification With Gene-Environment Interactions in Disease Modeling \- PubMed, 访问时间为 八月 18, 2025， [https://pubmed.ncbi.nlm.nih.gov/39865593/](https://pubmed.ncbi.nlm.nih.gov/39865593/)  
13. ML-Net: multi-label classification of biomedical texts with deep neural networks | Journal of the American Medical Informatics Association | Oxford Academic, 访问时间为 八月 18, 2025， [https://academic.oup.com/jamia/article/26/11/1279/5522430](https://academic.oup.com/jamia/article/26/11/1279/5522430)  
14. HMIC: Hierarchical Medical Image Classification, A Deep Learning ..., 访问时间为 八月 18, 2025， [https://pmc.ncbi.nlm.nih.gov/articles/PMC8346231/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8346231/)  
15. Severity-Based Hierarchical ECG Classification Using Neural Networks \- TU Delft Research Portal, 访问时间为 八月 18, 2025， [https://research.tudelft.nl/files/150772807/Severity\_Based\_Hierarchical\_ECG\_Classification\_Using\_Neural\_Networks.pdf](https://research.tudelft.nl/files/150772807/Severity_Based_Hierarchical_ECG_Classification_Using_Neural_Networks.pdf)  
16. Hierarchical Attention Network for Interpretable ECG-based Heart Disease Classification \- arXiv, 访问时间为 八月 18, 2025， [https://arxiv.org/html/2504.03703v1](https://arxiv.org/html/2504.03703v1)  
17. Hierarchical Attention Network for Interpretable ECG-based ... \- arXiv, 访问时间为 八月 18, 2025， [https://arxiv.org/pdf/2504.03703](https://arxiv.org/pdf/2504.03703)  
18. ECG-Signal Multi-Classification Model Based on Squeeze-and ..., 访问时间为 八月 18, 2025， [https://www.mdpi.com/2076-3417/10/18/6495](https://www.mdpi.com/2076-3417/10/18/6495)  
19. (PDF) ECG-Signal Multi-Classification Model Based on Squeeze-and-Excitation Residual Neural Networks \- ResearchGate, 访问时间为 八月 18, 2025， [https://www.researchgate.net/publication/345023541\_ECG-Signal\_Multi-Classification\_Model\_Based\_on\_Squeeze-and-Excitation\_Residual\_Neural\_Networks](https://www.researchgate.net/publication/345023541_ECG-Signal_Multi-Classification_Model_Based_on_Squeeze-and-Excitation_Residual_Neural_Networks)  
20. Causability and explainability of artificial intelligence in medicine \- PMC \- PubMed Central, 访问时间为 八月 18, 2025， [https://pmc.ncbi.nlm.nih.gov/articles/PMC7017860/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7017860/)  
21. Explainable Artificial Intelligence in the Medical Domain: A Systematic Review \- Beadle Scholar, 访问时间为 八月 18, 2025， [https://scholar.dsu.edu/cgi/viewcontent.cgi?article=1265\&context=bispapers](https://scholar.dsu.edu/cgi/viewcontent.cgi?article=1265&context=bispapers)  
22. Decision Tree in Machine Learning \- GeeksforGeeks, 访问时间为 八月 18, 2025， [https://www.geeksforgeeks.org/machine-learning/decision-tree-introduction-example/](https://www.geeksforgeeks.org/machine-learning/decision-tree-introduction-example/)  
23. Python | Decision tree implementation \- GeeksforGeeks, 访问时间为 八月 18, 2025， [https://www.geeksforgeeks.org/machine-learning/decision-tree-implementation-python/](https://www.geeksforgeeks.org/machine-learning/decision-tree-implementation-python/)  
24. 2504.13534v2.pdf  
25. Explainable Artificial Intelligence for Medical Applications: A Review \- arXiv, 访问时间为 八月 18, 2025， [https://arxiv.org/html/2412.01829v1](https://arxiv.org/html/2412.01829v1)  
26. Hierarchical confusion matrix for classification performance ... \- arXiv, 访问时间为 八月 18, 2025， [https://arxiv.org/pdf/2306.09461](https://arxiv.org/pdf/2306.09461)  
27. Natural Language Processing (NLP) \[A Complete Guide\] \- DeepLearning.AI, 访问时间为 八月 18, 2025， [https://www.deeplearning.ai/resources/natural-language-processing/](https://www.deeplearning.ai/resources/natural-language-processing/)  
28. What Is NLP (Natural Language Processing)? \- IBM, 访问时间为 八月 18, 2025， [https://www.ibm.com/think/topics/natural-language-processing](https://www.ibm.com/think/topics/natural-language-processing)  
29. Natural Language Processing with Machine Learning to Predict Outcomes after Ovarian Cancer Surgery \- PMC, 访问时间为 八月 18, 2025， [https://pmc.ncbi.nlm.nih.gov/articles/PMC7779704/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7779704/)  
30. 1.10. Decision Trees — scikit-learn 1.7.1 documentation, 访问时间为 八月 18, 2025， [https://scikit-learn.org/stable/modules/tree.html](https://scikit-learn.org/stable/modules/tree.html)  
31. Beginner's Guide To Decision Tree Classification Using Python \- Analytics Vidhya, 访问时间为 八月 18, 2025， [https://www.analyticsvidhya.com/blog/2021/04/beginners-guide-to-decision-tree-classification-using-python/](https://www.analyticsvidhya.com/blog/2021/04/beginners-guide-to-decision-tree-classification-using-python/)  
32. Python Decision Tree Classification Tutorial: Scikit-Learn DecisionTreeClassifier | DataCamp, 访问时间为 八月 18, 2025， [https://www.datacamp.com/tutorial/decision-tree-classification-python](https://www.datacamp.com/tutorial/decision-tree-classification-python)